{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting symbols from image using `OpenCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functools import cmp_to_key\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSymbols(imgOrig, showSteps = False):\n",
    "    debugImgSteps = []\n",
    "    imgGray = cv2.cvtColor(imgOrig,cv2.COLOR_BGR2GRAY)\n",
    "    imgFiltered = cv2.medianBlur(imgGray, 5)\n",
    "    debugImgSteps.append(imgFiltered)\n",
    "    \n",
    "    imgCanny = cv2.Canny(imgFiltered, 50,180)\n",
    "    debugImgSteps.append(imgCanny)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    imgDilated = cv2.dilate(imgCanny, kernel, iterations=5)\n",
    "    debugImgSteps.append(imgDilated)\n",
    "\n",
    "    contours, _= cv2.findContours(imgDilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    boundingBoxes = []\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        boundingBoxes.append((x,y,w,h))\n",
    "\n",
    "    global rowsG\n",
    "    rowsG, _, _ = imgOrig.shape\n",
    "    key_leftRightTopBottom = cmp_to_key(leftRightTopBottom)\n",
    "    boundingBoxes = sorted(boundingBoxes, key=key_leftRightTopBottom)\n",
    "\n",
    "    symbols = []\n",
    "    for (i, box) in enumerate(boundingBoxes):\n",
    "        x,y,w,h = box\n",
    "        mathSymbol = imgOrig[y:y+h, x:x+w]\n",
    "        mathSymbol = cv2.cvtColor(mathSymbol, cv2.COLOR_BGR2GRAY) #converting to Gray as tensorflow deals with grayscale or RGB, not BGR\n",
    "        mathSymbol = cv2.resize(mathSymbol, (45,45), interpolation=cv2.INTER_AREA) #to have the same size as trained images in the dataset\n",
    "        debugImgSteps.append(mathSymbol)\n",
    "        mathSymbolF = mathSymbol.astype('float32') #optional: tensorflows deals with float32, not uint8\n",
    "        symbols.append(mathSymbolF)\n",
    "\n",
    "    if showSteps:\n",
    "        dispImages(debugImgSteps)\n",
    "\n",
    "    return symbols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftRightTopBottom(tup1, tup2):\n",
    "    x1, y1, _, _ = tup1\n",
    "    x2, y2, _, _ = tup2\n",
    "    rows = rowsG\n",
    "    yRegion1, yRegion2 = -1, -1\n",
    "\n",
    "    for i in range(4):\n",
    "        if y1 < rows/4 + rows*(i/4):\n",
    "            yRegion1 = i\n",
    "            break\n",
    "    else:\n",
    "        if yRegion1 == -1:\n",
    "            yRegion1 = 4\n",
    "\n",
    "    for i in range(4):\n",
    "        if y2 < rows/4 + rows*(i/4):\n",
    "            yRegion2 = i\n",
    "            break\n",
    "    else:\n",
    "        if yRegion2 == -1:\n",
    "            yRegion2 = 4\n",
    "    \n",
    "    if yRegion1 < yRegion2:\n",
    "        return -1\n",
    "    elif yRegion2 < yRegion1:\n",
    "        return 1\n",
    "    elif x1 <= x2:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispImages(imgs):\n",
    "    for img in imgs:\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('tests/testMath6.png')\n",
    "symbols = extractSymbols(img, showSteps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dictionary that maps folder names to latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of folder names in \"mathSymbolsDataset\": <br>\n",
    "<img src=\"guideImages/datasetFolders.png\" width=400 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using `r` to make the string `raw` to avoid confusing strings like `\\n` with python's new line <br>\n",
    "however, the values will now have two backslashes (e.g. `\\\\n`), thus, we will later need to replace each `\\\\` with `\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    \"-\": r\"-\",\n",
    "    \"!\": r\"!\",\n",
    "    \"(\": r\"(\",\n",
    "    \")\": r\")\",\n",
    "    \",\": r\",\",\n",
    "    \"[\": r\"[\",\n",
    "    \"]\": r\"]\",\n",
    "    \"{\": r\"\\{\",\n",
    "    \"}\": r\"\\}\",\n",
    "    \"+\": r\"+\",\n",
    "    \"=\": r\"=\",\n",
    "    \"0\": r\"0\",\n",
    "    \"1\": r\"1\",\n",
    "    \"2\": r\"2\",\n",
    "    \"3\": r\"3\",\n",
    "    \"4\": r\"4\",\n",
    "    \"5\": r\"5\",\n",
    "    \"6\": r\"6\",\n",
    "    \"7\": r\"7\",\n",
    "    \"8\": r\"8\",\n",
    "    \"9\": r\"9\",\n",
    "    \"A\": r\"\\A\",\n",
    "    \"alpha\": r\"\\alpha\",\n",
    "    \"b\": r\"b\",\n",
    "    \"beta\": r\"\\beta\",\n",
    "    \"C\": r\"\\C\",\n",
    "    \"cos\": r\"\\cos\",\n",
    "    \"d\": r\"d\",\n",
    "    \"Delta\": r\"\\Delta\",\n",
    "    \"div\": r\"\\div\",\n",
    "    \"e\": r\"exp()\",\n",
    "    \"exists\": r\"\\exists\",\n",
    "    \"f\": r\"f\",\n",
    "    \"forall\": r\"\\forall\",\n",
    "    \"forward_slash\": r\"/\",\n",
    "    \"G\": r\"\\G\",\n",
    "    \"gamma\": r\"\\gamma\",\n",
    "    \"geq\": r\"\\geq\",\n",
    "    \"gt\": r\">\",\n",
    "    \"H\": r\"\\H\",\n",
    "    \"i\": r\"i\",\n",
    "    \"in\": r\"\\in\",\n",
    "    \"infty\": r\"\\infty\",\n",
    "    \"int\": r\"\\int\",\n",
    "    \"j\": r\"j\",\n",
    "    \"k\": r\"k\",\n",
    "    \"l\": r\"l\",\n",
    "    \"lambda\": r\"\\lambda\",\n",
    "    \"ldots\": r\"\\ldots\",\n",
    "    \"leq\": r\"\\le\",\n",
    "    \"lim\": r\"\\lim\",\n",
    "    \"log\": r\"\\log\",\n",
    "    \"lt\": r\"<\",\n",
    "    \"M\": r\"\\M\",\n",
    "    \"mu\": r\"\\mu\",\n",
    "    \"N\": r\"\\N\",\n",
    "    \"neq\": r\"\\neq\",\n",
    "    \"o\": r\"\\O\",\n",
    "    \"p\": r\"p\",\n",
    "    \"phi\": r\"\\Phi\",\n",
    "    \"pi\": r\"\\Pi\",\n",
    "    \"pm\": r\"\\pm\",\n",
    "    \"q\": r\"q\",\n",
    "    \"R\": r\"\\R\",\n",
    "    \"rightarrow\": r\"\\rightarrow\",\n",
    "    \"S\": r\"\\S\",\n",
    "    \"sigma\": r\"\\sigma\",\n",
    "    \"sin\": r\"\\sin\",\n",
    "    \"sum\": r\"\\sum\",\n",
    "    \"T\": r\"\\T\",\n",
    "    \"tan\": r\"\\tan\",\n",
    "    \"theta\": r\"\\theta\",\n",
    "    \"times\": r\"\\times\",\n",
    "    \"u\": r\"u\",\n",
    "    \"v\": r\"v\",\n",
    "    \"w\": r\"w\",\n",
    "    \"X\": r\"\\X\",\n",
    "    \"y\": r\"y\",\n",
    "    \"z\": r\"z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the kaggle [dataset](https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols?resource=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. create a list of images and another list of labels for each image\n",
    "2. store them in pickle files for easy retrieval when re-running the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dataDir):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for key, value in dic.items():\n",
    "        path = os.path.join(dataDir, key)\n",
    "        for imgName in os.listdir(path):\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(path, imgName), cv2.COLOR_BGR2GRAY) \n",
    "                imgs.append(img)\n",
    "                labels.append(value)\n",
    "            except Exception as e:\n",
    "                print(e)    \n",
    "    return (imgs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is commented as it takes a long time (10min if image RGB, 1min otherwise) to create the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs, labels = loadData('mathSymbolsDataset/')\n",
    "#with open(\"x_symbols.pickle\", 'wb') as f:\n",
    "#    pickle.dump(imgs, f)\n",
    "#with open(\"y_latex.pickle\", 'wb') as f:\n",
    "#    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_symbols.pickle\", 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "with open(\"y_latex.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting text labels (latex) to numeric codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 0,\n",
       " '(': 1,\n",
       " ')': 2,\n",
       " '+': 3,\n",
       " ',': 4,\n",
       " '-': 5,\n",
       " '/': 6,\n",
       " '0': 7,\n",
       " '1': 8,\n",
       " '2': 9,\n",
       " '3': 10,\n",
       " '4': 11,\n",
       " '5': 12,\n",
       " '6': 13,\n",
       " '7': 14,\n",
       " '8': 15,\n",
       " '9': 16,\n",
       " '<': 17,\n",
       " '=': 18,\n",
       " '>': 19,\n",
       " '[': 20,\n",
       " '\\\\A': 21,\n",
       " '\\\\C': 22,\n",
       " '\\\\Delta': 23,\n",
       " '\\\\G': 24,\n",
       " '\\\\H': 25,\n",
       " '\\\\M': 26,\n",
       " '\\\\N': 27,\n",
       " '\\\\O': 28,\n",
       " '\\\\Phi': 29,\n",
       " '\\\\Pi': 30,\n",
       " '\\\\R': 31,\n",
       " '\\\\S': 32,\n",
       " '\\\\T': 33,\n",
       " '\\\\X': 34,\n",
       " '\\\\alpha': 35,\n",
       " '\\\\beta': 36,\n",
       " '\\\\cos': 37,\n",
       " '\\\\div': 38,\n",
       " '\\\\exists': 39,\n",
       " '\\\\forall': 40,\n",
       " '\\\\gamma': 41,\n",
       " '\\\\geq': 42,\n",
       " '\\\\in': 43,\n",
       " '\\\\infty': 44,\n",
       " '\\\\int': 45,\n",
       " '\\\\lambda': 46,\n",
       " '\\\\ldots': 47,\n",
       " '\\\\le': 48,\n",
       " '\\\\lim': 49,\n",
       " '\\\\log': 50,\n",
       " '\\\\mu': 51,\n",
       " '\\\\neq': 52,\n",
       " '\\\\pm': 53,\n",
       " '\\\\rightarrow': 54,\n",
       " '\\\\sigma': 55,\n",
       " '\\\\sin': 56,\n",
       " '\\\\sum': 57,\n",
       " '\\\\tan': 58,\n",
       " '\\\\theta': 59,\n",
       " '\\\\times': 60,\n",
       " '\\\\{': 61,\n",
       " '\\\\}': 62,\n",
       " ']': 63,\n",
       " 'b': 64,\n",
       " 'd': 65,\n",
       " 'exp()': 66,\n",
       " 'f': 67,\n",
       " 'i': 68,\n",
       " 'j': 69,\n",
       " 'k': 70,\n",
       " 'l': 71,\n",
       " 'p': 72,\n",
       " 'q': 73,\n",
       " 'u': 74,\n",
       " 'v': 75,\n",
       " 'w': 76,\n",
       " 'y': 77,\n",
       " 'z': 78}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latexToNums = {k: v for v, k in enumerate(np.unique(labels))}\n",
    "#this dictionary is to revert the predicted numeric code back to latex: \n",
    "numsToLatex = {v: k for v, k in enumerate(np.unique(labels))}\n",
    "latexToNums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `stratify` is used to split the dataset into train and test sets <br> \n",
    "in a way that preserves the same proportions of examples in each class as observed in the original dataset <br>\n",
    "[(source)](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/#:~:text=is%20desirable%20to-,split%20the%20dataset%20into,stratified%20train-test%20split.,-We%20can%20achieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.33, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing image pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1) #similar to dividing by 255 (but not equivalent in result)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1) #Also, don't know why we are using \"axis=1\" specifically, but that's what's normally used with image normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `y` labels to numeric codes instead of strings\n",
    "Because `keras` models accept numbers not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispImages([x_train[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58,\n",
       " 65,\n",
       " 10,\n",
       " 62,\n",
       " 5,\n",
       " 9,\n",
       " 31,\n",
       " 34,\n",
       " 77,\n",
       " 3,\n",
       " 34,\n",
       " 5,\n",
       " 11,\n",
       " 9,\n",
       " 34,\n",
       " 30,\n",
       " 21,\n",
       " 5,\n",
       " 5,\n",
       " 14,\n",
       " 27,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 77,\n",
       " 64,\n",
       " 21,\n",
       " 34,\n",
       " 8,\n",
       " 34,\n",
       " 3,\n",
       " 27,\n",
       " 16,\n",
       " 67,\n",
       " 5,\n",
       " 18,\n",
       " 34,\n",
       " 3,\n",
       " 77,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 18,\n",
       " 56,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 34,\n",
       " 5,\n",
       " 45,\n",
       " 9,\n",
       " 15,\n",
       " 60,\n",
       " 8,\n",
       " 11,\n",
       " 50,\n",
       " 8,\n",
       " 1,\n",
       " 22,\n",
       " 21,\n",
       " 9,\n",
       " 21,\n",
       " 63,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 26,\n",
       " 31,\n",
       " 60,\n",
       " 9,\n",
       " 3,\n",
       " 18,\n",
       " 3,\n",
       " 34,\n",
       " 8,\n",
       " 5,\n",
       " 66,\n",
       " 34,\n",
       " 21,\n",
       " 15,\n",
       " 30,\n",
       " 49,\n",
       " 5,\n",
       " 10,\n",
       " 3,\n",
       " 14,\n",
       " 5,\n",
       " 7,\n",
       " 18,\n",
       " 67,\n",
       " 49,\n",
       " 37,\n",
       " 37,\n",
       " 16,\n",
       " 10,\n",
       " 5,\n",
       " 56,\n",
       " 15,\n",
       " 5,\n",
       " 10,\n",
       " 11,\n",
       " 2,\n",
       " 22,\n",
       " 8,\n",
       " 64,\n",
       " 73,\n",
       " 27,\n",
       " 66,\n",
       " 22,\n",
       " 8,\n",
       " 59,\n",
       " 36,\n",
       " 34,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 77,\n",
       " 8,\n",
       " 18,\n",
       " 30,\n",
       " 26,\n",
       " 3,\n",
       " 70,\n",
       " 16,\n",
       " 18,\n",
       " 64,\n",
       " 1,\n",
       " 78,\n",
       " 1,\n",
       " 5,\n",
       " 34,\n",
       " 34,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 60,\n",
       " 1,\n",
       " 12,\n",
       " 36,\n",
       " 5,\n",
       " 23,\n",
       " 5,\n",
       " 27,\n",
       " 34,\n",
       " 8,\n",
       " 0,\n",
       " 49,\n",
       " 34,\n",
       " 9,\n",
       " 3,\n",
       " 48,\n",
       " 5,\n",
       " 57,\n",
       " 59,\n",
       " 3,\n",
       " 2,\n",
       " 21,\n",
       " 69,\n",
       " 21,\n",
       " 49,\n",
       " 3,\n",
       " 34,\n",
       " 12,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 73,\n",
       " 34,\n",
       " 5,\n",
       " 5,\n",
       " 41,\n",
       " 24,\n",
       " 3,\n",
       " 3,\n",
       " 14,\n",
       " 64,\n",
       " 27,\n",
       " 77,\n",
       " 34,\n",
       " 7,\n",
       " 58,\n",
       " 50,\n",
       " 22,\n",
       " 7,\n",
       " 26,\n",
       " 10,\n",
       " 68,\n",
       " 5,\n",
       " 5,\n",
       " 78,\n",
       " 3,\n",
       " 59,\n",
       " 12,\n",
       " 77,\n",
       " 78,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 50,\n",
       " 47,\n",
       " 65,\n",
       " 5,\n",
       " 72,\n",
       " 37,\n",
       " 3,\n",
       " 3,\n",
       " 34,\n",
       " 37,\n",
       " 9,\n",
       " 56,\n",
       " 9,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 14,\n",
       " 27,\n",
       " 37,\n",
       " 64,\n",
       " 5,\n",
       " 5,\n",
       " 27,\n",
       " 59,\n",
       " 45,\n",
       " 16,\n",
       " 38,\n",
       " 2,\n",
       " 12,\n",
       " 68,\n",
       " 21,\n",
       " 11,\n",
       " 36,\n",
       " 12,\n",
       " 8,\n",
       " 34,\n",
       " 9,\n",
       " 34,\n",
       " 2,\n",
       " 1,\n",
       " 74,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 27,\n",
       " 3,\n",
       " 34,\n",
       " 10,\n",
       " 8,\n",
       " 68,\n",
       " 3,\n",
       " 22,\n",
       " 70,\n",
       " 60,\n",
       " 14,\n",
       " 2,\n",
       " 24,\n",
       " 3,\n",
       " 34,\n",
       " 48,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 72,\n",
       " 3,\n",
       " 72,\n",
       " 31,\n",
       " 18,\n",
       " 5,\n",
       " 3,\n",
       " 18,\n",
       " 78,\n",
       " 9,\n",
       " 5,\n",
       " 18,\n",
       " 63,\n",
       " 9,\n",
       " 9,\n",
       " 18,\n",
       " 3,\n",
       " 5,\n",
       " 64,\n",
       " 77,\n",
       " 64,\n",
       " 32,\n",
       " 9,\n",
       " 65,\n",
       " 18,\n",
       " 5,\n",
       " 68,\n",
       " 1,\n",
       " 34,\n",
       " 8,\n",
       " 5,\n",
       " 34,\n",
       " 21,\n",
       " 14,\n",
       " 44,\n",
       " 37,\n",
       " 21,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 34,\n",
       " 78,\n",
       " 18,\n",
       " 18,\n",
       " 42,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 32,\n",
       " 68,\n",
       " 5,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 72,\n",
       " 68,\n",
       " 5,\n",
       " 77,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 10,\n",
       " 62,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 18,\n",
       " 36,\n",
       " 67,\n",
       " 5,\n",
       " 29,\n",
       " 1,\n",
       " 21,\n",
       " 4,\n",
       " 8,\n",
       " 66,\n",
       " 8,\n",
       " 78,\n",
       " 11,\n",
       " 73,\n",
       " 34,\n",
       " 65,\n",
       " 5,\n",
       " 18,\n",
       " 72,\n",
       " 60,\n",
       " 9,\n",
       " 34,\n",
       " 37,\n",
       " 3,\n",
       " 10,\n",
       " 26,\n",
       " 8,\n",
       " 36,\n",
       " 2,\n",
       " 56,\n",
       " 5,\n",
       " 65,\n",
       " 11,\n",
       " 16,\n",
       " 34,\n",
       " 3,\n",
       " 18,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 57,\n",
       " 3,\n",
       " 56,\n",
       " 9,\n",
       " 34,\n",
       " 2,\n",
       " 72,\n",
       " 5,\n",
       " 37,\n",
       " 73,\n",
       " 15,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 21,\n",
       " 65,\n",
       " 34,\n",
       " 34,\n",
       " 18,\n",
       " 65,\n",
       " 3,\n",
       " 8,\n",
       " 78,\n",
       " 57,\n",
       " 7,\n",
       " 64,\n",
       " 57,\n",
       " 8,\n",
       " 2,\n",
       " 67,\n",
       " 9,\n",
       " 75,\n",
       " 10,\n",
       " 75,\n",
       " 2,\n",
       " 2,\n",
       " 27,\n",
       " 72,\n",
       " 27,\n",
       " 12,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 34,\n",
       " 18,\n",
       " 71,\n",
       " 8,\n",
       " 34,\n",
       " 56,\n",
       " 18,\n",
       " 7,\n",
       " 65,\n",
       " 8,\n",
       " 70,\n",
       " 12,\n",
       " 9,\n",
       " 7,\n",
       " 15,\n",
       " 33,\n",
       " 59,\n",
       " 21,\n",
       " 63,\n",
       " 9,\n",
       " 21,\n",
       " 34,\n",
       " 44,\n",
       " 78,\n",
       " 42,\n",
       " 11,\n",
       " 3,\n",
       " 5,\n",
       " 34,\n",
       " 9,\n",
       " 11,\n",
       " 21,\n",
       " 8,\n",
       " 34,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 34,\n",
       " 27,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 77,\n",
       " 1,\n",
       " 48,\n",
       " 8,\n",
       " 64,\n",
       " 8,\n",
       " 5,\n",
       " 59,\n",
       " 9,\n",
       " 34,\n",
       " 3,\n",
       " 67,\n",
       " 34,\n",
       " 2,\n",
       " 21,\n",
       " 3,\n",
       " 34,\n",
       " 1,\n",
       " 21,\n",
       " 77,\n",
       " 8,\n",
       " 27,\n",
       " 49,\n",
       " 27,\n",
       " 26,\n",
       " 32,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 34,\n",
       " 27,\n",
       " 77,\n",
       " 5,\n",
       " 56,\n",
       " 1,\n",
       " 7,\n",
       " 18,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 77,\n",
       " 5,\n",
       " 70,\n",
       " 3,\n",
       " 37,\n",
       " 1,\n",
       " 34,\n",
       " 5,\n",
       " 5,\n",
       " 21,\n",
       " 5,\n",
       " 9,\n",
       " 29,\n",
       " 13,\n",
       " 8,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 57,\n",
       " 11,\n",
       " 8,\n",
       " 14,\n",
       " 13,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 55,\n",
       " 9,\n",
       " 27,\n",
       " 21,\n",
       " 34,\n",
       " 5,\n",
       " 13,\n",
       " 25,\n",
       " 10,\n",
       " 3,\n",
       " 34,\n",
       " 9,\n",
       " 9,\n",
       " 74,\n",
       " 2,\n",
       " 34,\n",
       " 5,\n",
       " 7,\n",
       " 27,\n",
       " 34,\n",
       " 8,\n",
       " 2,\n",
       " 14,\n",
       " 78,\n",
       " 18,\n",
       " 69,\n",
       " 78,\n",
       " 2,\n",
       " 5,\n",
       " 41,\n",
       " 7,\n",
       " 21,\n",
       " 57,\n",
       " 78,\n",
       " 3,\n",
       " 78,\n",
       " 12,\n",
       " 5,\n",
       " 18,\n",
       " 53,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 70,\n",
       " 12,\n",
       " 13,\n",
       " 21,\n",
       " 11,\n",
       " 8,\n",
       " 18,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 67,\n",
       " 2,\n",
       " 8,\n",
       " 59,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 11,\n",
       " 49,\n",
       " 2,\n",
       " 21,\n",
       " 8,\n",
       " 58,\n",
       " 9,\n",
       " 31,\n",
       " 59,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 77,\n",
       " 8,\n",
       " 3,\n",
       " 68,\n",
       " 34,\n",
       " 27,\n",
       " 9,\n",
       " 21,\n",
       " 16,\n",
       " 67,\n",
       " 45,\n",
       " 76,\n",
       " 20,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 67,\n",
       " 9,\n",
       " 1,\n",
       " 11,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 77,\n",
       " 3,\n",
       " 21,\n",
       " 53,\n",
       " 5,\n",
       " 65,\n",
       " 16,\n",
       " 27,\n",
       " 3,\n",
       " 15,\n",
       " 2,\n",
       " 18,\n",
       " 5,\n",
       " 34,\n",
       " 15,\n",
       " 2,\n",
       " 65,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 77,\n",
       " 36,\n",
       " 16,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 22,\n",
       " 3,\n",
       " 10,\n",
       " 5,\n",
       " 72,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 60,\n",
       " 1,\n",
       " 67,\n",
       " 30,\n",
       " 3,\n",
       " 13,\n",
       " 9,\n",
       " 34,\n",
       " 47,\n",
       " 11,\n",
       " 10,\n",
       " 48,\n",
       " 67,\n",
       " 34,\n",
       " 33,\n",
       " 27,\n",
       " 9,\n",
       " 3,\n",
       " 78,\n",
       " 9,\n",
       " 34,\n",
       " 64,\n",
       " 5,\n",
       " 5,\n",
       " 34,\n",
       " 10,\n",
       " 2,\n",
       " 10,\n",
       " 26,\n",
       " 5,\n",
       " 1,\n",
       " 30,\n",
       " 5,\n",
       " 59,\n",
       " 5,\n",
       " 34,\n",
       " 11,\n",
       " 60,\n",
       " 34,\n",
       " 8,\n",
       " 8,\n",
       " 22,\n",
       " 52,\n",
       " 8,\n",
       " 10,\n",
       " 1,\n",
       " 11,\n",
       " 5,\n",
       " 78,\n",
       " 9,\n",
       " 69,\n",
       " 21,\n",
       " 21,\n",
       " 1,\n",
       " 34,\n",
       " 4,\n",
       " 34,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 45,\n",
       " 8,\n",
       " 31,\n",
       " 68,\n",
       " 10,\n",
       " 64,\n",
       " 56,\n",
       " 77,\n",
       " 1,\n",
       " 77,\n",
       " 66,\n",
       " 60,\n",
       " 2,\n",
       " 36,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 64,\n",
       " 34,\n",
       " 5,\n",
       " 34,\n",
       " 34,\n",
       " 65,\n",
       " 34,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 21,\n",
       " 9,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 8,\n",
       " 69,\n",
       " 42,\n",
       " 3,\n",
       " 34,\n",
       " 75,\n",
       " 2,\n",
       " 16,\n",
       " 8,\n",
       " 0,\n",
       " 64,\n",
       " 68,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 10,\n",
       " 50,\n",
       " 3,\n",
       " 68,\n",
       " 5,\n",
       " 26,\n",
       " 8,\n",
       " 34,\n",
       " 72,\n",
       " 3,\n",
       " 13,\n",
       " 5,\n",
       " 21,\n",
       " 14,\n",
       " 8,\n",
       " 18,\n",
       " 64,\n",
       " 38,\n",
       " 34,\n",
       " 8,\n",
       " 34,\n",
       " 25,\n",
       " 34,\n",
       " 34,\n",
       " 9,\n",
       " 65,\n",
       " 34,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 21,\n",
       " 3,\n",
       " 9,\n",
       " 21,\n",
       " 21,\n",
       " 73,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 31,\n",
       " 21,\n",
       " 78,\n",
       " 5,\n",
       " 34,\n",
       " 8,\n",
       " 9,\n",
       " 74,\n",
       " 7,\n",
       " 34,\n",
       " 65,\n",
       " 60,\n",
       " 65,\n",
       " 9,\n",
       " 67,\n",
       " 22,\n",
       " 3,\n",
       " 9,\n",
       " 54,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 27,\n",
       " 11,\n",
       " 27,\n",
       " 69,\n",
       " 61,\n",
       " 1,\n",
       " 2,\n",
       " 59,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 27,\n",
       " 34,\n",
       " 5,\n",
       " 34,\n",
       " 21,\n",
       " 45,\n",
       " 16,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 33,\n",
       " 5,\n",
       " 56,\n",
       " 56,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 32,\n",
       " 11,\n",
       " 27,\n",
       " 64,\n",
       " 68,\n",
       " 72,\n",
       " 11,\n",
       " 34,\n",
       " 3,\n",
       " 3,\n",
       " 10,\n",
       " 34,\n",
       " 31,\n",
       " 7,\n",
       " 21,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 30,\n",
       " 72,\n",
       " 21,\n",
       " 8,\n",
       " 18,\n",
       " 54,\n",
       " 1,\n",
       " 34,\n",
       " 16,\n",
       " 56,\n",
       " 70,\n",
       " 18,\n",
       " 37,\n",
       " 8,\n",
       " 2,\n",
       " 77,\n",
       " 65,\n",
       " 64,\n",
       " 27,\n",
       " 57,\n",
       " 1,\n",
       " 9,\n",
       " 18,\n",
       " 5,\n",
       " 18,\n",
       " 21,\n",
       " 27,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 22,\n",
       " 64,\n",
       " 78,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 10,\n",
       " 9,\n",
       " 34,\n",
       " 9,\n",
       " 60,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 64,\n",
       " 32,\n",
       " 9,\n",
       " 31,\n",
       " 34,\n",
       " 31,\n",
       " 33,\n",
       " 45,\n",
       " 2,\n",
       " 68,\n",
       " 21,\n",
       " 67,\n",
       " 27,\n",
       " 27,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 5,\n",
       " 44,\n",
       " 5,\n",
       " 54,\n",
       " 37,\n",
       " 12,\n",
       " 9,\n",
       " 37,\n",
       " 18,\n",
       " 70,\n",
       " 11,\n",
       " 11,\n",
       " 5,\n",
       " 12,\n",
       " 10,\n",
       " 34,\n",
       " 1,\n",
       " 5,\n",
       " 77,\n",
       " 1,\n",
       " 72,\n",
       " 34,\n",
       " 78,\n",
       " 1,\n",
       " 67,\n",
       " 25,\n",
       " 8,\n",
       " 68,\n",
       " 21,\n",
       " 37,\n",
       " 52,\n",
       " 72,\n",
       " 37,\n",
       " 34,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nums = [latexToNums[latex] for latex in y_train]\n",
    "y_test_nums = [latexToNums[latex] for latex in y_test]\n",
    "y_train_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure all datasets are `ndarray` not `list`\n",
    "Because `keras` models accept `ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, list, list)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(x_test), type(y_train_nums), type(y_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nums = np.array(y_train_nums)\n",
    "y_test_nums = np.array(y_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_nums), type(y_test_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sequential vs Functional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential is a linear stack of layers. In other words, the layer `i` is connected only to layers `i-1` and `i+1`\n",
    "* Functional is more dynamic, as each layer can connect to any other layer in the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the images are small in size, and the problem is relatively simple, we'll use a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easier processing: flatten image (e.g. 45x45 will become 1x2025)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# 128 nodes are chosen as they are a power of 2 (2^7) which makes computation easier, and the images are not large (45x45) so 128 nodes should suffice\n",
    "# relu is the default activation function to use\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# add another layer because if you have one, then you're getting linear relations only between the image's features, while two layers makes it non-linear\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# number of classifications == number of stored latex strings == len(latexToNums) == 79\n",
    "# using softmax as it converts the scores to a normalized probability distribution\n",
    "model.add(tf.keras.layers.Dense(len(latexToNums), activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"compiling\" means passing the settings for actually optimizing/training the model we've defined\n",
    "model.compile(optimizer='adam', # same logic as relu, great default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy', # A neural network doesn't actually attempt to maximize accuracy. It attempts to minimize loss, this loss function is also a great default\n",
    "              metrics=['accuracy']) # ratio between the number of correct predictions to the total number of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A good rule of thumb is to start with a value that is 3 times the number of columns in your data.\" <br>\n",
    "[(source)](https://gretel.ai/gretel-synthetics-faqs/how-many-epochs-should-i-train-my-model-with) <br>\n",
    "Therefore, we start by with 45*3 = 135 epochs (i.e. number of passes of the entire training dataset the machine learning algorithm has completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train_nums, epochs=135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the model for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical note: pickle doesn't save models correctly, as it outputs this error when loading the pickle file: <br><br>\n",
    "FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://0eb44777-6983-466e-ac15-adfa9d3dae07/variables/variables\n",
    " You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'. <br><br>\n",
    " That's why we are using keras's `save()` and `load_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"nnModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"nnModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45, 45)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[0].reshape(1,45,45).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "symTest = symbols[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symTest.reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c1111f16a5ca6766f1c5cccb819e55c234e2449b101cca4e6a0a62df2327c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
