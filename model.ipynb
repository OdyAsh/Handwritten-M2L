{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting symbols from image using `OpenCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functools import cmp_to_key\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSymbols(imgOrig, showSteps = False):\n",
    "    debugImgSteps = []\n",
    "    imgGray = cv2.cvtColor(imgOrig,cv2.COLOR_BGR2GRAY)\n",
    "    imgFiltered = cv2.medianBlur(imgGray, 5)\n",
    "    debugImgSteps.append(imgFiltered)\n",
    "    \n",
    "    imgCanny = cv2.Canny(imgFiltered, 50,180)\n",
    "    debugImgSteps.append(imgCanny)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    imgDilated = cv2.dilate(imgCanny, kernel, iterations=5)\n",
    "    debugImgSteps.append(imgDilated)\n",
    "\n",
    "    contours, _= cv2.findContours(imgDilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    boundingBoxes = []\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        boundingBoxes.append((x,y,w,h))\n",
    "\n",
    "    global rowsG\n",
    "    rowsG, _, _ = imgOrig.shape\n",
    "    key_leftRightTopBottom = cmp_to_key(leftRightTopBottom)\n",
    "    boundingBoxes = sorted(boundingBoxes, key=key_leftRightTopBottom)\n",
    "\n",
    "    symbols = []\n",
    "    for (i, box) in enumerate(boundingBoxes):\n",
    "        x,y,w,h = box\n",
    "        mathSymbol = imgOrig[y:y+h, x:x+w]\n",
    "        mathSymbol = cv2.cvtColor(mathSymbol, cv2.COLOR_BGR2GRAY) #converting to Gray as tensorflow deals with grayscale or RGB, not BGR\n",
    "        mathSymbol = cv2.resize(mathSymbol, (45,45), interpolation=cv2.INTER_AREA) #to have the same size as trained images in the dataset\n",
    "        debugImgSteps.append(mathSymbol)\n",
    "        mathSymbolF = mathSymbol.astype('float32') #optional: tensorflows deals with float32, not uint8\n",
    "        symbols.append(mathSymbolF)\n",
    "\n",
    "    if showSteps:\n",
    "        dispImages(debugImgSteps)\n",
    "\n",
    "    return symbols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftRightTopBottom(tup1, tup2):\n",
    "    x1, y1, _, _ = tup1\n",
    "    x2, y2, _, _ = tup2\n",
    "    rows = rowsG\n",
    "    yRegion1, yRegion2 = -1, -1\n",
    "\n",
    "    for i in range(8):\n",
    "        if y1 < rows/8 + rows*(i/8):\n",
    "            yRegion1 = i\n",
    "            break\n",
    "    else:\n",
    "        if yRegion1 == -1:\n",
    "            yRegion1 = 8\n",
    "\n",
    "    for i in range(8):\n",
    "        if y2 < rows/8 + rows*(i/8):\n",
    "            yRegion2 = i\n",
    "            break\n",
    "    else:\n",
    "        if yRegion2 == -1:\n",
    "            yRegion2 = 8\n",
    "    \n",
    "    if yRegion1 < yRegion2:\n",
    "        return -1\n",
    "    elif yRegion2 < yRegion1:\n",
    "        return 1\n",
    "    elif x1 <= x2:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispImages(imgs):\n",
    "    for img in imgs:\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('tests/testMath6.png')\n",
    "symbols = extractSymbols(img, showSteps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dictionary that maps folder names to latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of folder names in \"mathSymbolsDataset\": <br>\n",
    "<img src=\"guideImages/datasetFolders.png\" width=400 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using `r` to make the string `raw` to avoid confusing strings like `\\n` with python's new line <br>\n",
    "however, the values will now have two backslashes (e.g. `\\\\n`), thus, we will later need to replace each `\\\\` with `\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    \"-\": r\"-\",\n",
    "    \"!\": r\"!\",\n",
    "    \"(\": r\"(\",\n",
    "    \")\": r\")\",\n",
    "    \",\": r\",\",\n",
    "    \"[\": r\"[\",\n",
    "    \"]\": r\"]\",\n",
    "    \"{\": r\"\\{\",\n",
    "    \"}\": r\"\\}\",\n",
    "    \"+\": r\"+\",\n",
    "    \"=\": r\"=\",\n",
    "    \"0\": r\"0\",\n",
    "    \"1\": r\"1\",\n",
    "    \"2\": r\"2\",\n",
    "    \"3\": r\"3\",\n",
    "    \"4\": r\"4\",\n",
    "    \"5\": r\"5\",\n",
    "    \"6\": r\"6\",\n",
    "    \"7\": r\"7\",\n",
    "    \"8\": r\"8\",\n",
    "    \"9\": r\"9\",\n",
    "    \"A\": r\"\\A\",\n",
    "    \"alpha\": r\"\\alpha\",\n",
    "    \"b\": r\"b\",\n",
    "    \"beta\": r\"\\beta\",\n",
    "    \"C\": r\"\\C\",\n",
    "    \"cos\": r\"\\cos\",\n",
    "    \"d\": r\"d\",\n",
    "    \"Delta\": r\"\\Delta\",\n",
    "    \"div\": r\"\\div\",\n",
    "    \"e\": r\"exp()\",\n",
    "    \"exists\": r\"\\exists\",\n",
    "    \"f\": r\"f\",\n",
    "    \"forall\": r\"\\forall\",\n",
    "    \"forward_slash\": r\"/\",\n",
    "    \"G\": r\"\\G\",\n",
    "    \"gamma\": r\"\\gamma\",\n",
    "    \"geq\": r\"\\geq\",\n",
    "    \"gt\": r\">\",\n",
    "    \"H\": r\"\\H\",\n",
    "    \"i\": r\"i\",\n",
    "    \"in\": r\"\\in\",\n",
    "    \"infty\": r\"\\infty\",\n",
    "    \"int\": r\"\\int\",\n",
    "    \"j\": r\"j\",\n",
    "    \"k\": r\"k\",\n",
    "    \"l\": r\"l\",\n",
    "    \"lambda\": r\"\\lambda\",\n",
    "    \"ldots\": r\"\\ldots\",\n",
    "    \"leq\": r\"\\le\",\n",
    "    \"lim\": r\"\\lim\",\n",
    "    \"log\": r\"\\log\",\n",
    "    \"lt\": r\"<\",\n",
    "    \"M\": r\"\\M\",\n",
    "    \"mu\": r\"\\mu\",\n",
    "    \"N\": r\"\\N\",\n",
    "    \"neq\": r\"\\neq\",\n",
    "    \"o\": r\"\\O\",\n",
    "    \"p\": r\"p\",\n",
    "    \"phi\": r\"\\Phi\",\n",
    "    \"pi\": r\"\\Pi\",\n",
    "    \"pm\": r\"\\pm\",\n",
    "    \"q\": r\"q\",\n",
    "    \"R\": r\"\\R\",\n",
    "    \"rightarrow\": r\"\\rightarrow\",\n",
    "    \"S\": r\"\\S\",\n",
    "    \"sigma\": r\"\\sigma\",\n",
    "    \"sin\": r\"\\sin\",\n",
    "    \"sum\": r\"\\sum\",\n",
    "    \"T\": r\"\\T\",\n",
    "    \"tan\": r\"\\tan\",\n",
    "    \"theta\": r\"\\theta\",\n",
    "    \"times\": r\"\\times\",\n",
    "    \"u\": r\"u\",\n",
    "    \"v\": r\"v\",\n",
    "    \"w\": r\"w\",\n",
    "    \"X\": r\"\\X\",\n",
    "    \"y\": r\"y\",\n",
    "    \"z\": r\"z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the kaggle [dataset](https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols?resource=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. create a list of images and another list of labels for each image\n",
    "2. store them in pickle files for easy retrieval when re-running the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dataDir):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for key, value in dic.items():\n",
    "        path = os.path.join(dataDir, key)\n",
    "        for imgName in os.listdir(path):\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(path, imgName), cv2.COLOR_BGR2GRAY) \n",
    "                imgs.append(img)\n",
    "                labels.append(value)\n",
    "            except Exception as e:\n",
    "                print(e)    \n",
    "    return (imgs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is commented as it takes a long time (10min if image RGB, 1min otherwise) to create the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs, labels = loadData('mathSymbolsDataset/')\n",
    "#with open(\"x_symbols.pickle\", 'wb') as f:\n",
    "#    pickle.dump(imgs, f)\n",
    "#with open(\"y_latex.pickle\", 'wb') as f:\n",
    "#    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_symbols.pickle\", 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "with open(\"y_latex.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting text labels (latex) to numeric codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 0,\n",
       " '(': 1,\n",
       " ')': 2,\n",
       " '+': 3,\n",
       " ',': 4,\n",
       " '-': 5,\n",
       " '/': 6,\n",
       " '0': 7,\n",
       " '1': 8,\n",
       " '2': 9,\n",
       " '3': 10,\n",
       " '4': 11,\n",
       " '5': 12,\n",
       " '6': 13,\n",
       " '7': 14,\n",
       " '8': 15,\n",
       " '9': 16,\n",
       " '<': 17,\n",
       " '=': 18,\n",
       " '>': 19,\n",
       " '[': 20,\n",
       " '\\\\A': 21,\n",
       " '\\\\C': 22,\n",
       " '\\\\Delta': 23,\n",
       " '\\\\G': 24,\n",
       " '\\\\H': 25,\n",
       " '\\\\M': 26,\n",
       " '\\\\N': 27,\n",
       " '\\\\O': 28,\n",
       " '\\\\Phi': 29,\n",
       " '\\\\Pi': 30,\n",
       " '\\\\R': 31,\n",
       " '\\\\S': 32,\n",
       " '\\\\T': 33,\n",
       " '\\\\X': 34,\n",
       " '\\\\alpha': 35,\n",
       " '\\\\beta': 36,\n",
       " '\\\\cos': 37,\n",
       " '\\\\div': 38,\n",
       " '\\\\exists': 39,\n",
       " '\\\\forall': 40,\n",
       " '\\\\gamma': 41,\n",
       " '\\\\geq': 42,\n",
       " '\\\\in': 43,\n",
       " '\\\\infty': 44,\n",
       " '\\\\int': 45,\n",
       " '\\\\lambda': 46,\n",
       " '\\\\ldots': 47,\n",
       " '\\\\le': 48,\n",
       " '\\\\lim': 49,\n",
       " '\\\\log': 50,\n",
       " '\\\\mu': 51,\n",
       " '\\\\neq': 52,\n",
       " '\\\\pm': 53,\n",
       " '\\\\rightarrow': 54,\n",
       " '\\\\sigma': 55,\n",
       " '\\\\sin': 56,\n",
       " '\\\\sum': 57,\n",
       " '\\\\tan': 58,\n",
       " '\\\\theta': 59,\n",
       " '\\\\times': 60,\n",
       " '\\\\{': 61,\n",
       " '\\\\}': 62,\n",
       " ']': 63,\n",
       " 'b': 64,\n",
       " 'd': 65,\n",
       " 'exp()': 66,\n",
       " 'f': 67,\n",
       " 'i': 68,\n",
       " 'j': 69,\n",
       " 'k': 70,\n",
       " 'l': 71,\n",
       " 'p': 72,\n",
       " 'q': 73,\n",
       " 'u': 74,\n",
       " 'v': 75,\n",
       " 'w': 76,\n",
       " 'y': 77,\n",
       " 'z': 78}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latexToNums = {k: v for v, k in enumerate(np.unique(labels))}\n",
    "#this dictionary is to revert the predicted numeric code back to latex: \n",
    "numsToLatex = {v: k for v, k in enumerate(np.unique(labels))}\n",
    "latexToNums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `stratify` is used to split the dataset into train and test sets <br> \n",
    "in a way that preserves the same proportions of examples in each class as observed in the original dataset <br>\n",
    "[(source)](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/#:~:text=is%20desirable%20to-,split%20the%20dataset%20into,stratified%20train-test%20split.,-We%20can%20achieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.33, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing image pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1) #similar to dividing by 255 (but not equivalent in result)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1) #Also, don't know why we are using \"axis=1\" specifically, but that's what's normally used with image normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `y` labels to numeric codes instead of strings\n",
    "Because `keras` models accept numbers not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispImages([x_train[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58,\n",
       " 65,\n",
       " 10,\n",
       " 62,\n",
       " 5,\n",
       " 9,\n",
       " 31,\n",
       " 34,\n",
       " 77,\n",
       " 3,\n",
       " 34,\n",
       " 5,\n",
       " 11,\n",
       " 9,\n",
       " 34,\n",
       " 30,\n",
       " 21,\n",
       " 5,\n",
       " 5,\n",
       " 14,\n",
       " 27,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 77,\n",
       " 64,\n",
       " 21,\n",
       " 34,\n",
       " 8,\n",
       " 34,\n",
       " 3,\n",
       " 27,\n",
       " 16,\n",
       " 67,\n",
       " 5,\n",
       " 18,\n",
       " 34,\n",
       " 3,\n",
       " 77,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 18,\n",
       " 56,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 34,\n",
       " 5,\n",
       " 45,\n",
       " 9,\n",
       " 15,\n",
       " 60,\n",
       " 8,\n",
       " 11,\n",
       " 50,\n",
       " 8,\n",
       " 1,\n",
       " 22,\n",
       " 21,\n",
       " 9,\n",
       " 21,\n",
       " 63,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 26,\n",
       " 31,\n",
       " 60,\n",
       " 9,\n",
       " 3,\n",
       " 18,\n",
       " 3,\n",
       " 34,\n",
       " 8,\n",
       " 5,\n",
       " 66,\n",
       " 34,\n",
       " 21,\n",
       " 15,\n",
       " 30,\n",
       " 49,\n",
       " 5,\n",
       " 10,\n",
       " 3,\n",
       " 14,\n",
       " 5,\n",
       " 7,\n",
       " 18,\n",
       " 67,\n",
       " 49,\n",
       " 37,\n",
       " 37,\n",
       " 16,\n",
       " 10,\n",
       " 5,\n",
       " 56,\n",
       " 15,\n",
       " 5,\n",
       " 10,\n",
       " 11,\n",
       " 2,\n",
       " 22,\n",
       " 8,\n",
       " 64,\n",
       " 73,\n",
       " 27,\n",
       " 66,\n",
       " 22,\n",
       " 8,\n",
       " 59,\n",
       " 36,\n",
       " 34,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 77,\n",
       " 8,\n",
       " 18,\n",
       " 30,\n",
       " 26,\n",
       " 3,\n",
       " 70,\n",
       " 16,\n",
       " 18,\n",
       " 64,\n",
       " 1,\n",
       " 78,\n",
       " 1,\n",
       " 5,\n",
       " 34,\n",
       " 34,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 60,\n",
       " 1,\n",
       " 12,\n",
       " 36,\n",
       " 5,\n",
       " 23,\n",
       " 5,\n",
       " 27,\n",
       " 34,\n",
       " 8,\n",
       " 0,\n",
       " 49,\n",
       " 34,\n",
       " 9,\n",
       " 3,\n",
       " 48,\n",
       " 5,\n",
       " 57,\n",
       " 59,\n",
       " 3,\n",
       " 2,\n",
       " 21,\n",
       " 69,\n",
       " 21,\n",
       " 49,\n",
       " 3,\n",
       " 34,\n",
       " 12,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 73,\n",
       " 34,\n",
       " 5,\n",
       " 5,\n",
       " 41,\n",
       " 24,\n",
       " 3,\n",
       " 3,\n",
       " 14,\n",
       " 64,\n",
       " 27,\n",
       " 77,\n",
       " 34,\n",
       " 7,\n",
       " 58,\n",
       " 50,\n",
       " 22,\n",
       " 7,\n",
       " 26,\n",
       " 10,\n",
       " 68,\n",
       " 5,\n",
       " 5,\n",
       " 78,\n",
       " 3,\n",
       " 59,\n",
       " 12,\n",
       " 77,\n",
       " 78,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 50,\n",
       " 47,\n",
       " 65,\n",
       " 5,\n",
       " 72,\n",
       " 37,\n",
       " 3,\n",
       " 3,\n",
       " 34,\n",
       " 37,\n",
       " 9,\n",
       " 56,\n",
       " 9,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 14,\n",
       " 27,\n",
       " 37,\n",
       " 64,\n",
       " 5,\n",
       " 5,\n",
       " 27,\n",
       " 59,\n",
       " 45,\n",
       " 16,\n",
       " 38,\n",
       " 2,\n",
       " 12,\n",
       " 68,\n",
       " 21,\n",
       " 11,\n",
       " 36,\n",
       " 12,\n",
       " 8,\n",
       " 34,\n",
       " 9,\n",
       " 34,\n",
       " 2,\n",
       " 1,\n",
       " 74,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 27,\n",
       " 3,\n",
       " 34,\n",
       " 10,\n",
       " 8,\n",
       " 68,\n",
       " 3,\n",
       " 22,\n",
       " 70,\n",
       " 60,\n",
       " 14,\n",
       " 2,\n",
       " 24,\n",
       " 3,\n",
       " 34,\n",
       " 48,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 72,\n",
       " 3,\n",
       " 72,\n",
       " 31,\n",
       " 18,\n",
       " 5,\n",
       " 3,\n",
       " 18,\n",
       " 78,\n",
       " 9,\n",
       " 5,\n",
       " 18,\n",
       " 63,\n",
       " 9,\n",
       " 9,\n",
       " 18,\n",
       " 3,\n",
       " 5,\n",
       " 64,\n",
       " 77,\n",
       " 64,\n",
       " 32,\n",
       " 9,\n",
       " 65,\n",
       " 18,\n",
       " 5,\n",
       " 68,\n",
       " 1,\n",
       " 34,\n",
       " 8,\n",
       " 5,\n",
       " 34,\n",
       " 21,\n",
       " 14,\n",
       " 44,\n",
       " 37,\n",
       " 21,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 34,\n",
       " 78,\n",
       " 18,\n",
       " 18,\n",
       " 42,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 32,\n",
       " 68,\n",
       " 5,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 72,\n",
       " 68,\n",
       " 5,\n",
       " 77,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 10,\n",
       " 62,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 18,\n",
       " 36,\n",
       " 67,\n",
       " 5,\n",
       " 29,\n",
       " 1,\n",
       " 21,\n",
       " 4,\n",
       " 8,\n",
       " 66,\n",
       " 8,\n",
       " 78,\n",
       " 11,\n",
       " 73,\n",
       " 34,\n",
       " 65,\n",
       " 5,\n",
       " 18,\n",
       " 72,\n",
       " 60,\n",
       " 9,\n",
       " 34,\n",
       " 37,\n",
       " 3,\n",
       " 10,\n",
       " 26,\n",
       " 8,\n",
       " 36,\n",
       " 2,\n",
       " 56,\n",
       " 5,\n",
       " 65,\n",
       " 11,\n",
       " 16,\n",
       " 34,\n",
       " 3,\n",
       " 18,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 57,\n",
       " 3,\n",
       " 56,\n",
       " 9,\n",
       " 34,\n",
       " 2,\n",
       " 72,\n",
       " 5,\n",
       " 37,\n",
       " 73,\n",
       " 15,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 21,\n",
       " 65,\n",
       " 34,\n",
       " 34,\n",
       " 18,\n",
       " 65,\n",
       " 3,\n",
       " 8,\n",
       " 78,\n",
       " 57,\n",
       " 7,\n",
       " 64,\n",
       " 57,\n",
       " 8,\n",
       " 2,\n",
       " 67,\n",
       " 9,\n",
       " 75,\n",
       " 10,\n",
       " 75,\n",
       " 2,\n",
       " 2,\n",
       " 27,\n",
       " 72,\n",
       " 27,\n",
       " 12,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 34,\n",
       " 18,\n",
       " 71,\n",
       " 8,\n",
       " 34,\n",
       " 56,\n",
       " 18,\n",
       " 7,\n",
       " 65,\n",
       " 8,\n",
       " 70,\n",
       " 12,\n",
       " 9,\n",
       " 7,\n",
       " 15,\n",
       " 33,\n",
       " 59,\n",
       " 21,\n",
       " 63,\n",
       " 9,\n",
       " 21,\n",
       " 34,\n",
       " 44,\n",
       " 78,\n",
       " 42,\n",
       " 11,\n",
       " 3,\n",
       " 5,\n",
       " 34,\n",
       " 9,\n",
       " 11,\n",
       " 21,\n",
       " 8,\n",
       " 34,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 34,\n",
       " 27,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 77,\n",
       " 1,\n",
       " 48,\n",
       " 8,\n",
       " 64,\n",
       " 8,\n",
       " 5,\n",
       " 59,\n",
       " 9,\n",
       " 34,\n",
       " 3,\n",
       " 67,\n",
       " 34,\n",
       " 2,\n",
       " 21,\n",
       " 3,\n",
       " 34,\n",
       " 1,\n",
       " 21,\n",
       " 77,\n",
       " 8,\n",
       " 27,\n",
       " 49,\n",
       " 27,\n",
       " 26,\n",
       " 32,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 34,\n",
       " 27,\n",
       " 77,\n",
       " 5,\n",
       " 56,\n",
       " 1,\n",
       " 7,\n",
       " 18,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 77,\n",
       " 5,\n",
       " 70,\n",
       " 3,\n",
       " 37,\n",
       " 1,\n",
       " 34,\n",
       " 5,\n",
       " 5,\n",
       " 21,\n",
       " 5,\n",
       " 9,\n",
       " 29,\n",
       " 13,\n",
       " 8,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 57,\n",
       " 11,\n",
       " 8,\n",
       " 14,\n",
       " 13,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 55,\n",
       " 9,\n",
       " 27,\n",
       " 21,\n",
       " 34,\n",
       " 5,\n",
       " 13,\n",
       " 25,\n",
       " 10,\n",
       " 3,\n",
       " 34,\n",
       " 9,\n",
       " 9,\n",
       " 74,\n",
       " 2,\n",
       " 34,\n",
       " 5,\n",
       " 7,\n",
       " 27,\n",
       " 34,\n",
       " 8,\n",
       " 2,\n",
       " 14,\n",
       " 78,\n",
       " 18,\n",
       " 69,\n",
       " 78,\n",
       " 2,\n",
       " 5,\n",
       " 41,\n",
       " 7,\n",
       " 21,\n",
       " 57,\n",
       " 78,\n",
       " 3,\n",
       " 78,\n",
       " 12,\n",
       " 5,\n",
       " 18,\n",
       " 53,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 70,\n",
       " 12,\n",
       " 13,\n",
       " 21,\n",
       " 11,\n",
       " 8,\n",
       " 18,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 67,\n",
       " 2,\n",
       " 8,\n",
       " 59,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 11,\n",
       " 49,\n",
       " 2,\n",
       " 21,\n",
       " 8,\n",
       " 58,\n",
       " 9,\n",
       " 31,\n",
       " 59,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 77,\n",
       " 8,\n",
       " 3,\n",
       " 68,\n",
       " 34,\n",
       " 27,\n",
       " 9,\n",
       " 21,\n",
       " 16,\n",
       " 67,\n",
       " 45,\n",
       " 76,\n",
       " 20,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 67,\n",
       " 9,\n",
       " 1,\n",
       " 11,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 77,\n",
       " 3,\n",
       " 21,\n",
       " 53,\n",
       " 5,\n",
       " 65,\n",
       " 16,\n",
       " 27,\n",
       " 3,\n",
       " 15,\n",
       " 2,\n",
       " 18,\n",
       " 5,\n",
       " 34,\n",
       " 15,\n",
       " 2,\n",
       " 65,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 77,\n",
       " 36,\n",
       " 16,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 22,\n",
       " 3,\n",
       " 10,\n",
       " 5,\n",
       " 72,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 60,\n",
       " 1,\n",
       " 67,\n",
       " 30,\n",
       " 3,\n",
       " 13,\n",
       " 9,\n",
       " 34,\n",
       " 47,\n",
       " 11,\n",
       " 10,\n",
       " 48,\n",
       " 67,\n",
       " 34,\n",
       " 33,\n",
       " 27,\n",
       " 9,\n",
       " 3,\n",
       " 78,\n",
       " 9,\n",
       " 34,\n",
       " 64,\n",
       " 5,\n",
       " 5,\n",
       " 34,\n",
       " 10,\n",
       " 2,\n",
       " 10,\n",
       " 26,\n",
       " 5,\n",
       " 1,\n",
       " 30,\n",
       " 5,\n",
       " 59,\n",
       " 5,\n",
       " 34,\n",
       " 11,\n",
       " 60,\n",
       " 34,\n",
       " 8,\n",
       " 8,\n",
       " 22,\n",
       " 52,\n",
       " 8,\n",
       " 10,\n",
       " 1,\n",
       " 11,\n",
       " 5,\n",
       " 78,\n",
       " 9,\n",
       " 69,\n",
       " 21,\n",
       " 21,\n",
       " 1,\n",
       " 34,\n",
       " 4,\n",
       " 34,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 45,\n",
       " 8,\n",
       " 31,\n",
       " 68,\n",
       " 10,\n",
       " 64,\n",
       " 56,\n",
       " 77,\n",
       " 1,\n",
       " 77,\n",
       " 66,\n",
       " 60,\n",
       " 2,\n",
       " 36,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 64,\n",
       " 34,\n",
       " 5,\n",
       " 34,\n",
       " 34,\n",
       " 65,\n",
       " 34,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 21,\n",
       " 9,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 8,\n",
       " 69,\n",
       " 42,\n",
       " 3,\n",
       " 34,\n",
       " 75,\n",
       " 2,\n",
       " 16,\n",
       " 8,\n",
       " 0,\n",
       " 64,\n",
       " 68,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 10,\n",
       " 50,\n",
       " 3,\n",
       " 68,\n",
       " 5,\n",
       " 26,\n",
       " 8,\n",
       " 34,\n",
       " 72,\n",
       " 3,\n",
       " 13,\n",
       " 5,\n",
       " 21,\n",
       " 14,\n",
       " 8,\n",
       " 18,\n",
       " 64,\n",
       " 38,\n",
       " 34,\n",
       " 8,\n",
       " 34,\n",
       " 25,\n",
       " 34,\n",
       " 34,\n",
       " 9,\n",
       " 65,\n",
       " 34,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 21,\n",
       " 3,\n",
       " 9,\n",
       " 21,\n",
       " 21,\n",
       " 73,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 31,\n",
       " 21,\n",
       " 78,\n",
       " 5,\n",
       " 34,\n",
       " 8,\n",
       " 9,\n",
       " 74,\n",
       " 7,\n",
       " 34,\n",
       " 65,\n",
       " 60,\n",
       " 65,\n",
       " 9,\n",
       " 67,\n",
       " 22,\n",
       " 3,\n",
       " 9,\n",
       " 54,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 27,\n",
       " 11,\n",
       " 27,\n",
       " 69,\n",
       " 61,\n",
       " 1,\n",
       " 2,\n",
       " 59,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 27,\n",
       " 34,\n",
       " 5,\n",
       " 34,\n",
       " 21,\n",
       " 45,\n",
       " 16,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 33,\n",
       " 5,\n",
       " 56,\n",
       " 56,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 32,\n",
       " 11,\n",
       " 27,\n",
       " 64,\n",
       " 68,\n",
       " 72,\n",
       " 11,\n",
       " 34,\n",
       " 3,\n",
       " 3,\n",
       " 10,\n",
       " 34,\n",
       " 31,\n",
       " 7,\n",
       " 21,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 30,\n",
       " 72,\n",
       " 21,\n",
       " 8,\n",
       " 18,\n",
       " 54,\n",
       " 1,\n",
       " 34,\n",
       " 16,\n",
       " 56,\n",
       " 70,\n",
       " 18,\n",
       " 37,\n",
       " 8,\n",
       " 2,\n",
       " 77,\n",
       " 65,\n",
       " 64,\n",
       " 27,\n",
       " 57,\n",
       " 1,\n",
       " 9,\n",
       " 18,\n",
       " 5,\n",
       " 18,\n",
       " 21,\n",
       " 27,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 22,\n",
       " 64,\n",
       " 78,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 10,\n",
       " 9,\n",
       " 34,\n",
       " 9,\n",
       " 60,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 64,\n",
       " 32,\n",
       " 9,\n",
       " 31,\n",
       " 34,\n",
       " 31,\n",
       " 33,\n",
       " 45,\n",
       " 2,\n",
       " 68,\n",
       " 21,\n",
       " 67,\n",
       " 27,\n",
       " 27,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 5,\n",
       " 44,\n",
       " 5,\n",
       " 54,\n",
       " 37,\n",
       " 12,\n",
       " 9,\n",
       " 37,\n",
       " 18,\n",
       " 70,\n",
       " 11,\n",
       " 11,\n",
       " 5,\n",
       " 12,\n",
       " 10,\n",
       " 34,\n",
       " 1,\n",
       " 5,\n",
       " 77,\n",
       " 1,\n",
       " 72,\n",
       " 34,\n",
       " 78,\n",
       " 1,\n",
       " 67,\n",
       " 25,\n",
       " 8,\n",
       " 68,\n",
       " 21,\n",
       " 37,\n",
       " 52,\n",
       " 72,\n",
       " 37,\n",
       " 34,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nums = [latexToNums[latex] for latex in y_train]\n",
    "y_test_nums = [latexToNums[latex] for latex in y_test]\n",
    "y_train_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure all datasets are `ndarray` not `list`\n",
    "Because `keras` models accept `ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, list, list)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(x_test), type(y_train_nums), type(y_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nums = np.array(y_train_nums)\n",
    "y_test_nums = np.array(y_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_nums), type(y_test_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sequential vs Functional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential is a linear stack of layers. In other words, the layer `i` is connected only to layers `i-1` and `i+1`\n",
    "* Functional is more dynamic, as each layer can connect to any other layer in the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the images are small in size, and the problem is relatively simple, we'll use a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easier processing: flatten image (e.g. 45x45 will become 1x2025)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# 128 nodes are chosen as they are a power of 2 (2^7) which makes computation easier, and the images are not large (45x45) so 128 nodes should suffice\n",
    "# relu is the default activation function to use\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# add another layer because if you have one, then you're getting linear relations only between the image's features, while two layers makes it non-linear\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# number of classifications == number of stored latex strings == len(latexToNums) == 79\n",
    "# using softmax as it converts the scores to a normalized probability distribution\n",
    "model.add(tf.keras.layers.Dense(len(latexToNums), activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"compiling\" means passing the settings for actually optimizing/training the model we've defined\n",
    "model.compile(optimizer='adam', # same logic as relu, great default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy', # A neural network doesn't actually attempt to maximize accuracy. It attempts to minimize loss, this loss function is also a great default\n",
    "              metrics=['accuracy']) # ratio between the number of correct predictions to the total number of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A good rule of thumb is to start with a value that is 3 times the number of columns in your data.\" <br>\n",
    "[(source)](https://gretel.ai/gretel-synthetics-faqs/how-many-epochs-should-i-train-my-model-with) <br>\n",
    "Therefore, we start by with 45*3 = 135 epochs (i.e. number of passes of the entire training dataset the machine learning algorithm has completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train_nums, epochs=135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the model for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical note: pickle doesn't save models correctly, as it outputs this error when loading the pickle file: <br><br>\n",
    "FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://0eb44777-6983-466e-ac15-adfa9d3dae07/variables/variables\n",
    " You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'. <br><br>\n",
    " That's why we are using keras's `save()` and `load_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"nnModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"nnModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45, 45)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[0].reshape(1,45,45).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "symTest = symbols[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symTest.reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Farah's Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x290328bcd90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_original = np.copy(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255, 255, 255, ..., 255, 255, 255], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = x_train[i].reshape(45*45)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '\\\\tan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Farah\\Documents\\Handwritten-M2L\\model.ipynb Cell 59'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000065?line=0'>1</a>\u001b[0m y_train \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '\\\\tan'"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Farah\\AppData\\Local\\Temp\\ipykernel_22600\\4057371436.py\", line 9, in <cell line: 9>\n      new_model.fit(x_train, y_train, epochs=5)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\metrics.py\", line 720, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_969]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Farah\\Documents\\Handwritten-M2L\\model.ipynb Cell 60'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=0'>1</a>\u001b[0m new_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=1'>2</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m79\u001b[39m,input_shape\u001b[39m=\u001b[39m(\u001b[39m2025\u001b[39m,), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=2'>3</a>\u001b[0m     ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=3'>4</a>\u001b[0m new_model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=4'>5</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=6'>7</a>\u001b[0m     metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=7'>8</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Farah/Documents/Handwritten-M2L/model.ipynb#ch0000061?line=8'>9</a>\u001b[0m new_model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/Farah/Documents/Handwritten-M2L/venv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Farah\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Farah\\AppData\\Local\\Temp\\ipykernel_22600\\4057371436.py\", line 9, in <cell line: 9>\n      new_model.fit(x_train, y_train, epochs=5)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\Farah\\Documents\\Handwritten-M2L\\venv\\lib\\site-packages\\keras\\metrics.py\", line 720, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_969]"
     ]
    }
   ],
   "source": [
    "new_model = keras.Sequential([\n",
    "    keras.layers.Dense(79,input_shape=(2025,), activation='sigmoid')\n",
    "    ])\n",
    "new_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "new_model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c1111f16a5ca6766f1c5cccb819e55c234e2449b101cca4e6a0a62df2327c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
