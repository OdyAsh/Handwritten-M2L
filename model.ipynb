{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting symbols from image using `OpenCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functools import cmp_to_key\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these functions have small logic differences <br> \n",
    "between them and the functions in `imgPreProcess.py` <br>\n",
    "This is for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSymbols(imgOrig, showSteps = False, verticalSymbols = False):\n",
    "    debugImgSteps = []\n",
    "    imgGray = cv2.cvtColor(imgOrig,cv2.COLOR_BGR2GRAY)\n",
    "    imgFiltered = cv2.medianBlur(imgGray, 5)\n",
    "    debugImgSteps.append(imgFiltered)\n",
    "    \n",
    "    imgCanny = cv2.Canny(imgFiltered, 50,180)\n",
    "    debugImgSteps.append(imgCanny)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    imgDilated = cv2.dilate(imgCanny, kernel, iterations=5)\n",
    "    debugImgSteps.append(imgDilated)\n",
    "\n",
    "    contours, _= cv2.findContours(imgDilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    boundingBoxes = []\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        boundingBoxes.append((x,y,w,h))\n",
    "\n",
    "    global rowsG\n",
    "    rowsG, _, _ = imgOrig.shape\n",
    "    key_leftRightTopBottom = cmp_to_key(leftRightTopBottom)\n",
    "    if (verticalSymbols):\n",
    "        boundingBoxes = sorted(boundingBoxes, key=key_leftRightTopBottom)\n",
    "    else:\n",
    "        boundingBoxes = sorted(boundingBoxes, key=lambda x : x[0])\n",
    "\n",
    "    symbols = []\n",
    "    for box in boundingBoxes:\n",
    "        x,y,w,h = box\n",
    "        mathSymbol = imgOrig[y:y+h, x:x+w]\n",
    "        mathSymbol = cv2.cvtColor(mathSymbol, cv2.COLOR_BGR2GRAY) #converting to Gray as tensorflow deals with grayscale or RGB, not BGR\n",
    "        mathSymbol = cv2.resize(mathSymbol, (45,45), interpolation=cv2.INTER_AREA) #to have the same size as trained images in the dataset\n",
    "        debugImgSteps.append(mathSymbol)\n",
    "        mathSymbolF = mathSymbol.astype('float32') #optional: tensorflows deals with float32, not uint8\n",
    "        symbols.append(mathSymbolF)\n",
    "\n",
    "    if showSteps:\n",
    "        dispImages(debugImgSteps)\n",
    "\n",
    "    return symbols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftRightTopBottom(tup1, tup2):\n",
    "    x1, y1, _, _ = tup1\n",
    "    x2, y2, _, _ = tup2\n",
    "    rows = rowsG\n",
    "    yRegion1, yRegion2 = -1, -1\n",
    "\n",
    "    for i in range(4):\n",
    "        if y1 < rows/4 + rows*(i/4.0):\n",
    "            yRegion1 = i\n",
    "            break\n",
    "    else:\n",
    "        if yRegion1 == -1:\n",
    "            yRegion1 = 4\n",
    "\n",
    "    for i in range(4):\n",
    "        if y2 < rows/4 + rows*(i/4.0):\n",
    "            yRegion2 = i\n",
    "            break\n",
    "    else:\n",
    "        if yRegion2 == -1:\n",
    "            yRegion2 = 4\n",
    "    \n",
    "    if yRegion1 < yRegion2:\n",
    "        return -1\n",
    "    elif yRegion2 < yRegion1:\n",
    "        return 1\n",
    "    elif x1 <= x2:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispImages(imgs):\n",
    "    for img in imgs:\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('tests/test1.png')\n",
    "symbols = extractSymbols(img, showSteps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dictionary that maps folder names to latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of folder names in \"mathSymbolsDataset\": <br>\n",
    "<img src=\"guideImages/datasetFolders.png\" width=400 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using `r` to make the string `raw` to avoid confusing strings like `\\n` with python's new line <br>\n",
    "however, the values will now have two backslashes (e.g. `\\\\n`), thus, we will later need to replace each `\\\\` with `\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    \"-\": r\"-\",\n",
    "    \"(\": r\"(\",\n",
    "    \")\": r\")\",   \n",
    "    \"+\": r\"+\",\n",
    "    \"=\": r\"=\",\n",
    "    \"0\": r\"0\",\n",
    "    \"1\": r\"1\",\n",
    "    \"2\": r\"2\",\n",
    "    \"3\": r\"3\",\n",
    "    \"4\": r\"4\",\n",
    "    \"5\": r\"5\",\n",
    "    \"6\": r\"6\",\n",
    "    \"7\": r\"7\",\n",
    "    \"8\": r\"8\",\n",
    "    \"9\": r\"9\",\n",
    "    \"geq\": r\"\\geq\",\n",
    "    \"gt\": r\">\",\n",
    "    \"i\": r\"i\",\n",
    "    \"in\": r\"\\in\",\n",
    "    \"int\": r\"\\int\",\n",
    "    \"j\": r\"j\",\n",
    "    \"leq\": r\"\\le\",\n",
    "    \"lt\": r\"<\",\n",
    "    \"neq\": r\"\\neq\",\n",
    "    \"pi\": r\"\\Pi\",\n",
    "    \"sum\": r\"\\sum\",\n",
    "    \"theta\": r\"\\theta\",\n",
    "    \"times\": r\"\\times\",\n",
    "    \"w\": r\"w\",\n",
    "    \"X\": r\"\\X\",\n",
    "    \"y\": r\"y\",\n",
    "    \"z\": r\"z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the kaggle [dataset](https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols?resource=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. create a list of images and another list of labels for each image\n",
    "2. store them in pickle files for easy retrieval when re-running the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dataDir):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for key, value in dic.items():\n",
    "        path = os.path.join(dataDir, key)\n",
    "        for imgName in os.listdir(path):\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(path, imgName), cv2.COLOR_BGR2GRAY) \n",
    "                imgs.append(img)\n",
    "                labels.append(value)\n",
    "            except Exception as e:\n",
    "                print(e)    \n",
    "    return (imgs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is commented as it takes a long time (10min if image RGB, 1min otherwise) to create the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs, labels = loadData('mathSymbolsDataset/')\n",
    "#with open(\"x_symbols.pickle\", 'wb') as f:\n",
    "#    pickle.dump(imgs, f)\n",
    "#with open(\"y_latex.pickle\", 'wb') as f:\n",
    "#    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_symbols_reduced.pickle\", 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "with open(\"y_latex_reduced.pickle\", 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting text labels (latex) to numeric codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': 0,\n",
       " ')': 1,\n",
       " '+': 2,\n",
       " '-': 3,\n",
       " '0': 4,\n",
       " '1': 5,\n",
       " '2': 6,\n",
       " '3': 7,\n",
       " '4': 8,\n",
       " '5': 9,\n",
       " '6': 10,\n",
       " '7': 11,\n",
       " '8': 12,\n",
       " '9': 13,\n",
       " '<': 14,\n",
       " '=': 15,\n",
       " '>': 16,\n",
       " '\\\\Pi': 17,\n",
       " '\\\\X': 18,\n",
       " '\\\\geq': 19,\n",
       " '\\\\in': 20,\n",
       " '\\\\int': 21,\n",
       " '\\\\le': 22,\n",
       " '\\\\neq': 23,\n",
       " '\\\\sum': 24,\n",
       " '\\\\theta': 25,\n",
       " '\\\\times': 26,\n",
       " 'i': 27,\n",
       " 'j': 28,\n",
       " 'w': 29,\n",
       " 'y': 30,\n",
       " 'z': 31}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latexToNums = {k: v for v, k in enumerate(np.unique(labels))}\n",
    "#this dictionary is to revert the predicted numeric code back to latex: \n",
    "numsToLatex = {v: k for v, k in enumerate(np.unique(labels))}\n",
    "latexToNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsNums = [latexToNums[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `stratify` is used to split the dataset into train and test sets <br> \n",
    "in a way that preserves the same proportions of examples in each class as observed in the original dataset <br>\n",
    "[(source)](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/#:~:text=is%20desirable%20to-,split%20the%20dataset%20into,stratified%20train-test%20split.,-We%20can%20achieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.33, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing image pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1) #similar to dividing by 255 (but not equivalent in result)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1) #Also, don't know why we are using \"axis=1\" specifically, but that's what's normally used with image normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `y` labels to numeric codes instead of strings\n",
    "Because `keras` models accept numbers not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 18,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 31,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 15,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 25,\n",
       " 10,\n",
       " 15,\n",
       " 18,\n",
       " 2,\n",
       " 11,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 18,\n",
       " 15,\n",
       " 7,\n",
       " 5,\n",
       " 12,\n",
       " 15,\n",
       " 8,\n",
       " 15,\n",
       " 1,\n",
       " 19,\n",
       " 7,\n",
       " 18,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 12,\n",
       " 28,\n",
       " 1,\n",
       " 15,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 30,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 18,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 18,\n",
       " 18,\n",
       " 3,\n",
       " 4,\n",
       " 27,\n",
       " 26,\n",
       " 7,\n",
       " 18,\n",
       " 3,\n",
       " 15,\n",
       " 6,\n",
       " 3,\n",
       " 18,\n",
       " 1,\n",
       " 5,\n",
       " 15,\n",
       " 4,\n",
       " 18,\n",
       " 4,\n",
       " 18,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 15,\n",
       " 18,\n",
       " 17,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 13,\n",
       " 3,\n",
       " 19,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 27,\n",
       " 13,\n",
       " 7,\n",
       " 31,\n",
       " 30,\n",
       " 18,\n",
       " 3,\n",
       " 23,\n",
       " 18,\n",
       " 5,\n",
       " 17,\n",
       " 2,\n",
       " 13,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 26,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 16,\n",
       " 18,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 22,\n",
       " 3,\n",
       " 21,\n",
       " 2,\n",
       " 31,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 21,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 19,\n",
       " 18,\n",
       " 26,\n",
       " 13,\n",
       " 26,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 31,\n",
       " 24,\n",
       " 0,\n",
       " 3,\n",
       " 27,\n",
       " 30,\n",
       " 18,\n",
       " 30,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 18,\n",
       " 24,\n",
       " 6,\n",
       " 5,\n",
       " 18,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 31,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 30,\n",
       " 9,\n",
       " 30,\n",
       " 17,\n",
       " 3,\n",
       " 18,\n",
       " 27,\n",
       " 0,\n",
       " 0,\n",
       " 24,\n",
       " 26,\n",
       " 12,\n",
       " 6,\n",
       " 5,\n",
       " 28,\n",
       " 5,\n",
       " 28,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 26,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 15,\n",
       " 18,\n",
       " 7,\n",
       " 2,\n",
       " 31,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 31,\n",
       " 7,\n",
       " 24,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 17,\n",
       " 18,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 27,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 2,\n",
       " 18,\n",
       " 18,\n",
       " 3,\n",
       " 18,\n",
       " 1,\n",
       " 19,\n",
       " 27,\n",
       " 30,\n",
       " 18,\n",
       " 17,\n",
       " 13,\n",
       " 5,\n",
       " 15,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 6,\n",
       " 11,\n",
       " 6,\n",
       " 18,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 12,\n",
       " 18,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 18,\n",
       " 6,\n",
       " 3,\n",
       " 12,\n",
       " 11,\n",
       " 23,\n",
       " 26,\n",
       " 30,\n",
       " 1,\n",
       " 30,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 15,\n",
       " 3,\n",
       " 6,\n",
       " 26,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 17,\n",
       " 31,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 19,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 13,\n",
       " 30,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 10,\n",
       " 28,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 27,\n",
       " 18,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 31,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 13,\n",
       " 18,\n",
       " 3,\n",
       " 1,\n",
       " 18,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 31,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 30,\n",
       " 18,\n",
       " 18,\n",
       " 5,\n",
       " 18,\n",
       " 3,\n",
       " 30,\n",
       " 15,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 18,\n",
       " 8,\n",
       " 30,\n",
       " 5,\n",
       " 24,\n",
       " 2,\n",
       " 14,\n",
       " 1,\n",
       " 18,\n",
       " 4,\n",
       " 3,\n",
       " 16,\n",
       " 0,\n",
       " 5,\n",
       " 30,\n",
       " 14,\n",
       " 23,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 13,\n",
       " 3,\n",
       " 3,\n",
       " 18,\n",
       " 6,\n",
       " 2,\n",
       " 13,\n",
       " 15,\n",
       " 2,\n",
       " 18,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 15,\n",
       " 18,\n",
       " 18,\n",
       " 5,\n",
       " 4,\n",
       " 25,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 15,\n",
       " 2,\n",
       " 3,\n",
       " 30,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 25,\n",
       " 3,\n",
       " 26,\n",
       " 21,\n",
       " 18,\n",
       " 7,\n",
       " 0,\n",
       " 27,\n",
       " 2,\n",
       " 31,\n",
       " 31,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 25,\n",
       " 3,\n",
       " 5,\n",
       " 30,\n",
       " 1,\n",
       " 27,\n",
       " 18,\n",
       " 2,\n",
       " 18,\n",
       " 5,\n",
       " 7,\n",
       " 15,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 12,\n",
       " 5,\n",
       " 2,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 30,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 5,\n",
       " 28,\n",
       " 26,\n",
       " 30,\n",
       " 6,\n",
       " 12,\n",
       " 6,\n",
       " 18,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 18,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 18,\n",
       " 31,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 30,\n",
       " 25,\n",
       " 31,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 15,\n",
       " 18,\n",
       " 3,\n",
       " 18,\n",
       " 1,\n",
       " 17,\n",
       " 5,\n",
       " 3,\n",
       " 18,\n",
       " 15,\n",
       " 10,\n",
       " 30,\n",
       " 15,\n",
       " 3,\n",
       " 18,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 31,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 18,\n",
       " 12,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 30,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 30,\n",
       " 17,\n",
       " 11,\n",
       " 15,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 13,\n",
       " 5,\n",
       " 18,\n",
       " 12,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 25,\n",
       " 6,\n",
       " 2,\n",
       " 30,\n",
       " 8,\n",
       " 22,\n",
       " 7,\n",
       " 15,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 30,\n",
       " 30,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 3,\n",
       " 30,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 18,\n",
       " 3,\n",
       " 15,\n",
       " 11,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 18,\n",
       " 31,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 18,\n",
       " 27,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 30,\n",
       " 10,\n",
       " 3,\n",
       " 4,\n",
       " 30,\n",
       " 4,\n",
       " 18,\n",
       " 21,\n",
       " 24,\n",
       " 5,\n",
       " 3,\n",
       " 18,\n",
       " 18,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 18,\n",
       " 8,\n",
       " 13,\n",
       " 12,\n",
       " 18,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 15,\n",
       " 1,\n",
       " 27,\n",
       " 15,\n",
       " 10,\n",
       " 6,\n",
       " 18,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 13,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 15,\n",
       " 1,\n",
       " 18,\n",
       " 18,\n",
       " 27,\n",
       " 7,\n",
       " 3,\n",
       " 30,\n",
       " 0,\n",
       " 27,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 15,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 30,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 5,\n",
       " 18,\n",
       " 13,\n",
       " 1,\n",
       " 5,\n",
       " 25,\n",
       " 0,\n",
       " 2,\n",
       " 30,\n",
       " 9,\n",
       " 3,\n",
       " 18,\n",
       " 5,\n",
       " 18,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 30,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 18,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 3,\n",
       " 28,\n",
       " 5,\n",
       " 18,\n",
       " 1,\n",
       " 9,\n",
       " 31,\n",
       " 9,\n",
       " 15,\n",
       " 3,\n",
       " 15,\n",
       " 31,\n",
       " 0,\n",
       " 18,\n",
       " 6,\n",
       " 15,\n",
       " 3,\n",
       " 17,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 12,\n",
       " 18,\n",
       " 7,\n",
       " 4,\n",
       " 10,\n",
       " 15,\n",
       " 1,\n",
       " 6,\n",
       " 31,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 11,\n",
       " 21,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 25,\n",
       " 2,\n",
       " 18,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 18,\n",
       " 6,\n",
       " 15,\n",
       " 2,\n",
       " 13,\n",
       " 11,\n",
       " 18,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 15,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 27,\n",
       " 17,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 12,\n",
       " 3,\n",
       " 15,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 31,\n",
       " 6,\n",
       " 15,\n",
       " 6,\n",
       " 18,\n",
       " 0,\n",
       " 18,\n",
       " 5,\n",
       " 18,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 26,\n",
       " 0,\n",
       " 4,\n",
       " 18,\n",
       " 15,\n",
       " 5,\n",
       " 27,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 15,\n",
       " 30,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 15,\n",
       " 1,\n",
       " 31,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 31,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 30,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 13,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 26,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 31,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 13,\n",
       " 3,\n",
       " 15,\n",
       " 25,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 30,\n",
       " 18,\n",
       " 5,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 18,\n",
       " 18,\n",
       " 9,\n",
       " 15,\n",
       " 3,\n",
       " 31,\n",
       " 18,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 15,\n",
       " 15,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 17,\n",
       " 30,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 21,\n",
       " 19,\n",
       " 1,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 11,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 17,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 15,\n",
       " 30,\n",
       " 0,\n",
       " 18,\n",
       " 3,\n",
       " 23,\n",
       " 28,\n",
       " 3,\n",
       " 9,\n",
       " 26,\n",
       " 6,\n",
       " 3,\n",
       " 17,\n",
       " 15,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nums = [latexToNums[latex] for latex in y_train]\n",
    "y_test_nums = [latexToNums[latex] for latex in y_test]\n",
    "y_train_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure all datasets are `ndarray` not `list`\n",
    "Because `keras` models accept `ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, list, list)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(x_test), type(y_train_nums), type(y_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nums = np.array(y_train_nums)\n",
    "y_test_nums = np.array(y_test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_nums), type(y_test_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance measure here is the accuracy metric the NN model is. <br>\n",
    "Note that the loss function and metrics arguments in `model.compile` are considered the model's utility (evaluation) function <br>\n",
    "as they tell the model how effective the training on the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(2025, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(2025, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5465/5465 [==============================] - 282s 51ms/step - loss: 1.4541 - accuracy: 0.5773\n",
      "Epoch 2/5\n",
      "5465/5465 [==============================] - 281s 51ms/step - loss: 0.8027 - accuracy: 0.7626\n",
      "Epoch 3/5\n",
      "5465/5465 [==============================] - 288s 53ms/step - loss: 0.6237 - accuracy: 0.8137\n",
      "Epoch 4/5\n",
      "5465/5465 [==============================] - 286s 52ms/step - loss: 0.5004 - accuracy: 0.8504\n",
      "Epoch 5/5\n",
      "5465/5465 [==============================] - 268s 49ms/step - loss: 0.4243 - accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17168d96eb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_nums, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ThennModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"ThennModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model from Here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"ThennModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we had the image segmented and stored the symbols in the variable symbols so we will predict for each symbol and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symbols[0].reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking in the dictionary above, 18 matches to x which is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symbols[1].reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking in the dictionary above, 2 matches to + which is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symbols[2].reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking in the dictionary above, 30 matches to y which is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symbols[3].reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking in the dictionary above, 15 matches to = which is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symbols[4].reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking in the dictionary above, 4 matches to 0 which is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sequence of the symbols is in the sequence of the image segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Different Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Attempt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sequential vs Functional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential is a linear stack of layers. In other words, the layer `i` is connected only to layers `i-1` and `i+1`\n",
    "* Functional is more dynamic, as each layer can connect to any other layer in the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the images are small in size, and the problem is relatively simple, we'll use a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easier processing: flatten image (e.g. 45x45 will become 1x2025)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# 128 nodes are chosen as they are a power of 2 (2^7) which makes computation easier, and the images are not large (45x45) so 128 nodes should suffice\n",
    "# relu is the default activation function to use\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# add another layer because if you have one, then you're getting linear relations only between the image's features, while two layers makes it non-linear\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# number of classifications == number of stored latex strings == len(latexToNums) == 79\n",
    "# using softmax as it converts the scores to a normalized probability distribution\n",
    "model.add(tf.keras.layers.Dense(len(latexToNums), activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"compiling\" means passing the settings for actually optimizing/training the model we've defined\n",
    "model.compile(optimizer='adam', # same logic as relu, great default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy', # A neural network doesn't actually attempt to maximize accuracy. It attempts to minimize loss, this loss function is also a great default\n",
    "              metrics=['accuracy']) # ratio between the number of correct predictions to the total number of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A good rule of thumb is to start with a value that is 3 times the number of columns in your data.\" <br>\n",
    "[(source)](https://gretel.ai/gretel-synthetics-faqs/how-many-epochs-should-i-train-my-model-with) <br>\n",
    "Therefore, we start by with 45*3 = 135 epochs (i.e. number of passes of the entire training dataset the machine learning algorithm has completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train_nums, epochs=135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the model for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical note: pickle doesn't save models correctly, as it outputs this error when loading the pickle file: <br><br>\n",
    "FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://0eb44777-6983-466e-ac15-adfa9d3dae07/variables/variables\n",
    " You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'. <br><br>\n",
    " That's why we are using keras's `save()` and `load_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"nnModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"nnModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45, 45)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[0].reshape(1,45,45).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "symTest = symbols[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model.predict(symTest.reshape(1,45,45))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model wasn't accurate with the results so we tried to work with convolutional Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional neural network was seemingly a good solution at the time since it applies filters on the images to extract its features, but the problem is handwritten characters barely had features so it still wasn't accurate, and it caused some overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique, argmax\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from keras.utils.vis_utils  import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation  ='relu', input_shape=(45,45,1)))\n",
    "model.add(MaxPool2D((2,2))) \n",
    "#batch normalization, try averagepool\n",
    "#leak\n",
    "model.add(Conv2D(48, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2025, activation='relu'))\n",
    "model.add(Dense(79, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1722/1722 - 386s - loss: 0.6359 - accuracy: 0.8275 - val_loss: 0.2793 - val_accuracy: 0.9140 - 386s/epoch - 224ms/step\n",
      "Epoch 2/10\n",
      "1722/1722 - 418s - loss: 0.2386 - accuracy: 0.9268 - val_loss: 0.1760 - val_accuracy: 0.9441 - 418s/epoch - 243ms/step\n",
      "Epoch 3/10\n",
      "1722/1722 - 401s - loss: 0.1689 - accuracy: 0.9461 - val_loss: 0.1280 - val_accuracy: 0.9589 - 401s/epoch - 233ms/step\n",
      "Epoch 4/10\n",
      "1722/1722 - 423s - loss: 0.1312 - accuracy: 0.9569 - val_loss: 0.1148 - val_accuracy: 0.9613 - 423s/epoch - 246ms/step\n",
      "Epoch 5/10\n",
      "1722/1722 - 406s - loss: 0.1091 - accuracy: 0.9634 - val_loss: 0.0922 - val_accuracy: 0.9711 - 406s/epoch - 236ms/step\n",
      "Epoch 6/10\n",
      "1722/1722 - 410s - loss: 0.0934 - accuracy: 0.9684 - val_loss: 0.0835 - val_accuracy: 0.9761 - 410s/epoch - 238ms/step\n",
      "Epoch 7/10\n",
      "1722/1722 - 428s - loss: 0.0828 - accuracy: 0.9721 - val_loss: 0.0740 - val_accuracy: 0.9781 - 428s/epoch - 248ms/step\n",
      "Epoch 8/10\n",
      "1722/1722 - 430s - loss: 0.0739 - accuracy: 0.9752 - val_loss: 0.0722 - val_accuracy: 0.9804 - 430s/epoch - 250ms/step\n",
      "Epoch 9/10\n",
      "1722/1722 - 379s - loss: 0.0676 - accuracy: 0.9773 - val_loss: 0.0653 - val_accuracy: 0.9817 - 379s/epoch - 220ms/step\n",
      "Epoch 10/10\n",
      "1722/1722 - 363s - loss: 0.0623 - accuracy: 0.9791 - val_loss: 0.0603 - val_accuracy: 0.9833 - 363s/epoch - 211ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "x = model.fit(x_train, y_train_nums, epochs=10, batch_size=128, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"FModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"FModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to resources limitations, we couldn't run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Conv2D(64, (3,3), input_shape=x_train.shape))\n",
    "#model.add(Activation(\"relu\"))\n",
    "#model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3,3)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "#model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(64))\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation('sigmoid'))\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "#model.fit(x_train, y_train_nums, batch_size=128, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), activation  ='relu', input_shape=(45,45,1)))\n",
    "model.add(MaxPool2D((2,2))) #batch normalization, try averagepool\n",
    "#leak\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "#model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2025, activation='relu'))\n",
    "#model.add(Dense(2025, activation='relu'))\n",
    "BatchNormalization(axis=1)\n",
    "model.add(Dense(79, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1722/1722 - 536s - loss: 0.9281 - accuracy: 0.7486 - val_loss: 0.3709 - val_accuracy: 0.8863 - 536s/epoch - 311ms/step\n",
      "Epoch 2/10\n",
      "1722/1722 - 546s - loss: 0.4311 - accuracy: 0.8686 - val_loss: 0.2845 - val_accuracy: 0.9116 - 546s/epoch - 317ms/step\n",
      "Epoch 3/10\n",
      "1722/1722 - 517s - loss: 0.3508 - accuracy: 0.8897 - val_loss: 0.2320 - val_accuracy: 0.9252 - 517s/epoch - 300ms/step\n",
      "Epoch 4/10\n",
      "1722/1722 - 496s - loss: 0.3076 - accuracy: 0.9011 - val_loss: 0.2139 - val_accuracy: 0.9291 - 496s/epoch - 288ms/step\n",
      "Epoch 5/10\n",
      "1722/1722 - 531s - loss: 0.2768 - accuracy: 0.9098 - val_loss: 0.1982 - val_accuracy: 0.9345 - 531s/epoch - 309ms/step\n",
      "Epoch 6/10\n",
      "1722/1722 - 531s - loss: 0.2555 - accuracy: 0.9155 - val_loss: 0.1801 - val_accuracy: 0.9393 - 531s/epoch - 308ms/step\n",
      "Epoch 7/10\n",
      "1722/1722 - 535s - loss: 0.2383 - accuracy: 0.9213 - val_loss: 0.1676 - val_accuracy: 0.9434 - 535s/epoch - 311ms/step\n",
      "Epoch 8/10\n",
      "1722/1722 - 496s - loss: 0.2243 - accuracy: 0.9252 - val_loss: 0.1571 - val_accuracy: 0.9496 - 496s/epoch - 288ms/step\n",
      "Epoch 9/10\n",
      "1722/1722 - 470s - loss: 0.2133 - accuracy: 0.9288 - val_loss: 0.1466 - val_accuracy: 0.9514 - 470s/epoch - 273ms/step\n",
      "Epoch 10/10\n",
      "1722/1722 - 457s - loss: 0.2019 - accuracy: 0.9316 - val_loss: 0.1401 - val_accuracy: 0.9557 - 457s/epoch - 265ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "x = model.fit(x_train, y_train_nums, epochs=10, batch_size=128, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(symbols[0].reshape(1,45,45))\n",
    "print(argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: F1Model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"F1Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we discovred that our dataset is imbalanced and it caused over domination by some classes, we tried to create class weights to weight each class and balance it, yet it did not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 9577,\n",
       " 1: 9618,\n",
       " 2: 16825,\n",
       " 3: 22778,\n",
       " 4: 4632,\n",
       " 5: 17768,\n",
       " 6: 17514,\n",
       " 7: 7309,\n",
       " 8: 4955,\n",
       " 9: 2375,\n",
       " 10: 2089,\n",
       " 11: 1949,\n",
       " 12: 2056,\n",
       " 13: 2504,\n",
       " 14: 320,\n",
       " 15: 8780,\n",
       " 16: 173,\n",
       " 17: 1562,\n",
       " 18: 17818,\n",
       " 19: 464,\n",
       " 20: 31,\n",
       " 21: 1837,\n",
       " 22: 652,\n",
       " 23: 374,\n",
       " 24: 1802,\n",
       " 25: 1873,\n",
       " 26: 2178,\n",
       " 27: 3444,\n",
       " 28: 1029,\n",
       " 29: 373,\n",
       " 30: 6258,\n",
       " 31: 3933}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numLabels, counts = np.unique(y_train, return_counts=True)\n",
    "numLabelsToFreq = dict(zip(numLabels, counts))\n",
    "numLabelsToFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.378406599143782,\n",
       " 1: 2.368267831149927,\n",
       " 2: 1.3538187221396731,\n",
       " 3: 1.0,\n",
       " 4: 4.917530224525043,\n",
       " 5: 1.2819675821701937,\n",
       " 6: 1.3005595523581135,\n",
       " 7: 3.1164317964153785,\n",
       " 8: 4.596972754793138,\n",
       " 9: 9.590736842105263,\n",
       " 10: 10.903781713738631,\n",
       " 11: 11.687018984094408,\n",
       " 12: 11.078793774319067,\n",
       " 13: 9.09664536741214,\n",
       " 14: 50.0,\n",
       " 15: 2.5943052391799544,\n",
       " 16: 50.0,\n",
       " 17: 14.58258642765685,\n",
       " 18: 1.2783701874508924,\n",
       " 19: 49.09051724137931,\n",
       " 20: 50.0,\n",
       " 21: 12.399564507348938,\n",
       " 22: 34.93558282208589,\n",
       " 23: 50.0,\n",
       " 24: 12.640399556048834,\n",
       " 25: 12.161238654564869,\n",
       " 26: 10.45821854912764,\n",
       " 27: 6.6138211382113825,\n",
       " 28: 22.13605442176871,\n",
       " 29: 50.0,\n",
       " 30: 3.639821029082774,\n",
       " 31: 5.791507754894482}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxlabelImgs = max(numLabelsToFreq.values())\n",
    "labelWeights = {label : maxlabelImgs / float(numImgs) for label, numImgs in numLabelsToFreq.items()}\n",
    "for k,v in labelWeights.items():\n",
    "    if(v > 50):\n",
    "        labelWeights[k] = 50.0\n",
    "labelWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5465/5465 [==============================] - 120s 22ms/step - loss: 1.5544 - accuracy: 0.5430\n",
      "Epoch 2/10\n",
      "5465/5465 [==============================] - 120s 22ms/step - loss: 0.8703 - accuracy: 0.7398\n",
      "Epoch 3/10\n",
      "5465/5465 [==============================] - 134s 25ms/step - loss: 0.6568 - accuracy: 0.8006\n",
      "Epoch 4/10\n",
      "5465/5465 [==============================] - 147s 27ms/step - loss: 0.5453 - accuracy: 0.8328\n",
      "Epoch 5/10\n",
      "5465/5465 [==============================] - 142s 26ms/step - loss: 0.4646 - accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "5465/5465 [==============================] - 133s 24ms/step - loss: 0.4109 - accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "5465/5465 [==============================] - 147s 27ms/step - loss: 0.3661 - accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "5465/5465 [==============================] - 149s 27ms/step - loss: 0.3264 - accuracy: 0.8965\n",
      "Epoch 9/10\n",
      "5465/5465 [==============================] - 152s 28ms/step - loss: 0.2941 - accuracy: 0.9051\n",
      "Epoch 10/10\n",
      "5465/5465 [==============================] - 148s 27ms/step - loss: 0.2722 - accuracy: 0.9119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276b7a42eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1000, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1000, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1000, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nnModel4\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"nnModel4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"nnModel4\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85af8a8472993ce2b507c889893cea6dd7c56561ee4a48c34647ae35980712cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
